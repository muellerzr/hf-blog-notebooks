{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supercharged Searching on the ðŸ¤— Hub",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Supercharged Searching on the ðŸ¤— Hub**\n",
        "\n",
        "The `huggingface_hub` library is a light-weight interface that provides a progamatic approach to exploring the hosting endpoints Hugging Face provides. Specifically: models, datasets, and spaces.\n",
        "\n",
        "Up until now, searching on the Hub through this interface was tricky to pull of, and there were many aspects of it a user had to \"just know\" and get accustomed to it. \n",
        "\n",
        "In this article, we will be looking at a few exciting new features added to the `huggingface_hub` to help lower that bar and provide users with a friendly API to search for the models and datasets they want to use without leaving their Jupyter or Python interfaces."
      ],
      "metadata": {
        "id": "rm5eODVz-VC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Before we begin, if you do not have the latest version of the `huggingface_hub` library on your system please run the following cell:"
      ],
      "metadata": {
        "id": "R2aWsNe9-VVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQuoMjlJ-R9y"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub -U"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Situtating the Problem:\n",
        "\n",
        "First, let's imagine the scenario you are in. You'd like to find all models that the are hosted on the Hugging Face Hub that are for Text Classification, were trained on the GLUE dataset, and are compatible with PyTorch.\n",
        "\n",
        "You may simply just open https://huggingface.co/models and use the widgets on there, but this requires you leaving your IDE, scanning those results, and a few button clicks to get you the information you need.\n",
        "\n",
        "What if there were a solution to this without having to leave your IDE?\n",
        "\n",
        "This is where the `huggingface_hub` comes in.\n",
        "\n",
        "For those familiar with the library, you may already know that we can search for these type of models. However, getting the query right is a painful process of trial and error.\n",
        "\n",
        "Could we simplify that? Let's find out. "
      ],
      "metadata": {
        "id": "GBfdTeX7-ZAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding what we need\n",
        "\n",
        "First we'll import the `HfApi`, which is a class that helps us interact with the back-end hosting for Hugging Face. We can interact with the models, datasets, and more through it. Along with this, we'll import in a few helper classes: the `ModelFilter` and `ModelSearchArguments`"
      ],
      "metadata": {
        "id": "6P6h61DK_XWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi, ModelFilter, ModelSearchArguments\n",
        "\n",
        "api = HfApi()"
      ],
      "metadata": {
        "id": "FwMzCZT4-Xdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two classes can help us frame a solution to our above problem. The `ModelSearchArguments` class is a namespace-like one, that contains every single valid parameter we can searech for! \n",
        "\n",
        "Let's take a peek:"
      ],
      "metadata": {
        "id": "wgAREcwD_odJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args = ModelSearchArguments()\n",
        "\n",
        "model_args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDmntayr_nvA",
        "outputId": "733bdc30-b931-4e8c-9c7a-2103f9db8811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Available Attributes or Keys:\n",
              " * author\n",
              " * dataset\n",
              " * language\n",
              " * library\n",
              " * license\n",
              " * model_name\n",
              " * pipeline_tag\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see a varity of attributes available to us (more on how this magic is done later). If we were to categorize what we wanted, we could likely seperate them out as:\n",
        "\n",
        "- `pipeline_tag` (or task): Text Classification\n",
        "- `dataset`: GLUE\n",
        "- `library`: PyTorch\n",
        "\n",
        "Given this seperation, it would make sense that we would find them within our `model_args` we've declared:"
      ],
      "metadata": {
        "id": "5jLQcH3OAOGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args.pipeline_tag.TextClassification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PA-16cmdAMt8",
        "outputId": "97724448-e45e-4cae-c4a2-30ed28de1a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'text-classification'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_args.dataset.glue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dZxpYRvvAjX7",
        "outputId": "a829f30f-e5a9-44ef-e137-59a213f87267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dataset:glue'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_args.library.PyTorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8W4zo9kyAnUz",
        "outputId": "910aeeb9-731a-4c9b-997f-e777a52f7956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pytorch'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we begin to notice though is some of the convience wrapping we perform here. `ModelSearchArguments` (and the complimentary `DatasetSearchArguments`) have a human-readable interface for you to read, with formatted outputs the API wants, such as how the glue dataset should be searched with `dataset:glue`. \n",
        "\n",
        "This is key because without this \"cheat sheet\" of knowing how certain parameters should be written, you can very easily sit in frustration as you're trying to search for models with the API!\n",
        "\n",
        "Now that we know what the right parameters are, we can search the API easily:"
      ],
      "metadata": {
        "id": "726krEDmAqEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api.list_models(filter = (\n",
        "    model_args.pipeline_tag.TextClassification, \n",
        "    model_args.dataset.glue, \n",
        "    model_args.library.PyTorch)\n",
        ")[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZZRgD97C6gg",
        "outputId": "08b5a003-4e01-4be4-85c9-5f867f06fc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelInfo: {\n",
              "\tmodelId: Jiva/xlm-roberta-large-it-mnli\n",
              "\tsha: c6e64469ec4aa17fedbd1b2522256f90a90b5b86\n",
              "\tlastModified: 2021-12-10T14:56:38.000Z\n",
              "\ttags: ['pytorch', 'xlm-roberta', 'text-classification', 'it', 'dataset:multi_nli', 'dataset:glue', 'arxiv:1911.02116', 'transformers', 'tensorflow', 'license:mit', 'zero-shot-classification']\n",
              "\tpipeline_tag: zero-shot-classification\n",
              "\tsiblings: [ModelFile(rfilename='.gitattributes'), ModelFile(rfilename='README.md'), ModelFile(rfilename='config.json'), ModelFile(rfilename='pytorch_model.bin'), ModelFile(rfilename='sentencepiece.bpe.model'), ModelFile(rfilename='special_tokens_map.json'), ModelFile(rfilename='tokenizer.json'), ModelFile(rfilename='tokenizer_config.json')]\n",
              "\tconfig: None\n",
              "\tprivate: False\n",
              "\tdownloads: 680\n",
              "\tlibrary_name: transformers\n",
              "\tlikes: 1\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's a bit more readable, and there's no guessing involved with \"Did I get this parameter right?\""
      ],
      "metadata": {
        "id": "p1SqDAg2DDyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taking it up a Notch\n",
        "\n",
        "We saw how we could use the `ModelSearchArguments` and `DatasetSearchArguments` to remove the guesswork from when we want to search the Hub, but what about if we have a very complex, messy query?\n",
        "\n",
        "Such as:\n",
        "I want to search for all models trained for both `text-classification` and `zero-shot` classification, were trained on the Multi NLI and GLUE datasets, and are compatible with both PyTorch and TensorFlow (a more exact query to get the above model). \n",
        "\n",
        "To setup this query, we'll make use of the `ModelFilter` class. It's designed to handle these types of situations, so we don't need to scratch our heads:"
      ],
      "metadata": {
        "id": "tiIZwgSyDKLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args.pipeline_tag.Zero_ShotClassification"
      ],
      "metadata": {
        "id": "PsGtiyjTDwlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filt = ModelFilter(\n",
        "    task = [\"text-classification\", \"zero-shot-classification\"],\n",
        "    trained_dataset = [model_args.dataset.multi_nli, model_args.dataset.glue],\n",
        "    library = ['pytorch', 'tensorflow']\n",
        ")"
      ],
      "metadata": {
        "id": "0ktbT9TtB5yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api.list_models(filt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uifv2s_iELNy",
        "outputId": "3bc44d03-594e-4062-cfd3-2513b84a293d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ModelInfo: {\n",
              " \tmodelId: Jiva/xlm-roberta-large-it-mnli\n",
              " \tsha: c6e64469ec4aa17fedbd1b2522256f90a90b5b86\n",
              " \tlastModified: 2021-12-10T14:56:38.000Z\n",
              " \ttags: ['pytorch', 'xlm-roberta', 'text-classification', 'it', 'dataset:multi_nli', 'dataset:glue', 'arxiv:1911.02116', 'transformers', 'tensorflow', 'license:mit', 'zero-shot-classification']\n",
              " \tpipeline_tag: zero-shot-classification\n",
              " \tsiblings: [ModelFile(rfilename='.gitattributes'), ModelFile(rfilename='README.md'), ModelFile(rfilename='config.json'), ModelFile(rfilename='pytorch_model.bin'), ModelFile(rfilename='sentencepiece.bpe.model'), ModelFile(rfilename='special_tokens_map.json'), ModelFile(rfilename='tokenizer.json'), ModelFile(rfilename='tokenizer_config.json')]\n",
              " \tconfig: None\n",
              " \tprivate: False\n",
              " \tdownloads: 680\n",
              " \tlibrary_name: transformers\n",
              " \tlikes: 1\n",
              " }]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very quickly we see that it's a much more coordinated approach for searching through the API, with no added headache for you!"
      ],
      "metadata": {
        "id": "Zauwwf_rEslt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the magic?\n",
        "\n",
        "Very briefly we'll talk about the underlying magic at play that gives us this enum-dictionary-like datatype, the `AttributeDictionary`.\n",
        "\n",
        "Heavily inspired by the `AttrDict` class from the [fastcore](https://fastcore.fast.ai/basics.html#AttrDict) library, the general idea is we take a normal dictionary and supercharge it for *exploratory programming* by providing tab-completion for every key in the dictionary. \n",
        "\n",
        "As we saw earlier, this gets even stronger when we have nested dictionaries we can explore through, such as `model_args.dataset.glue`!\n",
        "\n",
        "> For those familiar with JavaScript, we mimic how the `object` class is working.\n",
        "\n",
        "This simple utility class can provide a much more user-focused experience when exploring nested datatypes and trying to understand what is there, such as the return of an API request!\n",
        "\n",
        "As mentioned before, we expand on the `AttrDict` in a few key ways:\n",
        "- You can delete keys with `del model_args[key]` *or* with `del model_args.key`\n",
        "- That clean `__repr__` we saw earlier \n",
        "\n",
        "One very key concept to note though, is that if a key contains a number or special character it **must** be indexed as a dictionary, and *not* as an object.\n",
        "\n"
      ],
      "metadata": {
        "id": "w0ZSzzAA5a33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub.utils.endpoint_helpers import AttributeDictionary"
      ],
      "metadata": {
        "id": "jvGcbfQO6xMt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A very brief example of this is if we have an `AttributeDictionary` with a key of `3_c`:"
      ],
      "metadata": {
        "id": "K918e5VW7CHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "|d = {\"a\":2, \"b\":3, \"3_c\":4}\n",
        "ad = AttributeDictionary(d)"
      ],
      "metadata": {
        "id": "-agAdvu361Gt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As an attribute\n",
        "ad.3_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "XQXvmzcL7A3A",
        "outputId": "4cde7f22-7e06-4c51-a8df-4d44c6dd69b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-c0fe109cf75d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ad.3_c\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As a dictionary key\n",
        "ad[\"3_c\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn2i9UqU7NSF",
        "outputId": "7fc9de12-9963-4812-bdf5-3486273bd263"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concluding thoughts"
      ],
      "metadata": {
        "id": "RqIl9JCs7Rg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hopefully by now you have a brief understanding of how this new searching API can directly impact your workflow and exploration of the Hub! Along with this, perhaps you know of a place in your code where the `AttributeDictionary` might be useful for you to use.\n",
        "\n",
        "From here, make sure to check out the official documentation on [Searching the Hub Efficiently](https://huggingface.co/docs/hub/searching-the-hub)!"
      ],
      "metadata": {
        "id": "B61MaM847Vjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XUd8NvFo7zEV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
