{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Supercharged Searching on the ðŸ¤— Hub**\n",
        "\n",
        "The `huggingface_hub` library is a light-weight interface that provides a progamatic approach to exploring the hosting endpoints Hugging Face provides. Specifically: models, datasets, and spaces.\n",
        "\n",
        "Up until now, searching on the Hub through this interface was tricky to pull of, and there were many aspects of it a user had to \"just know\" and get accustomed to it. \n",
        "\n",
        "In this article, we will be looking at a few exciting new features added to the `huggingface_hub` to help lower that bar and provide users with a friendly API to search for the models and datasets they want to use without leaving their Jupyter or Python interfaces."
      ],
      "metadata": {
        "id": "dfATMl_orcxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Before we begin, if you do not have the latest version of the `huggingface_hub` library on your system please run the following cell:"
      ],
      "metadata": {
        "id": "tYSLtWO7sdIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub -U"
      ],
      "metadata": {
        "id": "WO4w4CUUjUtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The `AttributeDictionary`\n",
        "\n",
        "A key foundation in how most of these new helpers work is understanding the new `AttributeDictionary` class that was introduced. It is heavily inspired and based on the [fastcore](https://fastcore.fast.ai/basics.html#AttrDict) `AttrDict` class, with some important distinctions we'll talk about later. \n",
        "\n",
        "The general idea of this class is we take a normal dictionary and supercharge it for *exploratory programming*, by providing tab-completion for every key in a dictionary. It also works with nested dictionaries as well!\n",
        "\n",
        "> This class mimics how the `object` class in JavaScript works"
      ],
      "metadata": {
        "id": "TMQJfd2ntR7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at an example:"
      ],
      "metadata": {
        "id": "XV9TPQ0qt-sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub.utils.endpoint_helpers import AttributeDictionary"
      ],
      "metadata": {
        "id": "jimisDT9sk57"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a small dictionary\n",
        "d = {\"a\":2, \"b\":\"This is b\", \"3_a\":\"A number\"}\n",
        "# Convert it to an `AttributeDictionary`\n",
        "ad = AttributeDictionary(d)"
      ],
      "metadata": {
        "id": "qxgoop6cuFjm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this we can now call the `keys` from our dictionary as both properties *or* as a key-lookup (with tab-completion):"
      ],
      "metadata": {
        "id": "DUYzmuGWuttA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As a normal dictionary\n",
        "ad[\"a\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AElZvuG1uMWa",
        "outputId": "c6c07f00-f9b5-42d0-d953-c938f57ac8a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As a property with tab-completion\n",
        "ad.a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7bXn79iuMg5",
        "outputId": "25bb3496-6b82-44c1-b634-2ad776c8bafd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tab-completion aspect gets even stronger when we deal with nested `AttributeDictionary` objects:"
      ],
      "metadata": {
        "id": "Ayref1wrvC2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = {\n",
        "    \"a\": \n",
        "     AttributeDictionary(\n",
        "         {\"first\": 1, \"second\": 2}\n",
        "         ), \n",
        "     \"b\": \n",
        "     AttributeDictionary(\n",
        "         {\"third\": 3, \"fourth\": 4}\n",
        "         )\n",
        "     }\n",
        "ad = AttributeDictionary(d)"
      ],
      "metadata": {
        "id": "w8F_LUq3u_h6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Go to `ad[\"a\"][\"first\"]`\n",
        "print(ad.a.first)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HI_lgpHvhQ7",
        "outputId": "511e8c2a-9fed-4891-9f0d-e921f3aa554f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned before, we expand on the ideas of `fastcore`'s `AttrDict` in a few ways:\n",
        "- We can delete keys with either `del ad[key]` or `del ad.key`\n",
        "- A cleaner `__repr__` is available, showing what keys support tab-completion\n",
        "\n",
        "Let's look at that second point a little more.\n",
        "\n",
        "In Python, properties cannot have any numbers or special characters. As a result, if an `AttributeDictionary`'s key has one, it will only be able to be indexed as a **dictionary** and *not* as an object, such as below:"
      ],
      "metadata": {
        "id": "XgXJtPMXwDRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = {\"a\":2, \"b\":3, \"3_c\":4}\n",
        "ad = AttributeDictionary(d)"
      ],
      "metadata": {
        "id": "VPPGPMiJvl59"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the __repr__\n",
        "ad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkddloUFwlH0",
        "outputId": "56bd66db-95ae-4f56-a9ef-c51f15c56f15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Available Attributes or Keys:\n",
              " * 3_c (Key only)\n",
              " * a\n",
              " * b\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that `3_c` can only be accessed as a key, since it has a number in it (shown visually below):"
      ],
      "metadata": {
        "id": "Jmm4PjUtwpIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As an attribute (fails)\n",
        "ad.3_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "MKWpKFlswoCl",
        "outputId": "934f9cf1-e71e-481c-80f0-5910a0b4096f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-b138ac5be6e2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ad.3_c\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As a dictionary key\n",
        "ad[\"3_c\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZZVnuTlww02",
        "outputId": "6037ea74-3527-42b9-fe50-e6747dd3664d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowing what we can search for: `SearchArguments`\n",
        "\n",
        "Now that we understand the `AttributeDictionary`, let's talk about one of the most important parts of this update: the `ModelSearchArguments` and `DatasetSearchArguments`!\n",
        "\n",
        "By using the power of the `AttributeDictionary`, these two classes search through all public models hosted on the Hub, and populate a nested dictionary for us to explore. \n",
        "\n",
        "Each of these nested dictionaries follow the same guiding principal:\n",
        "\n",
        "- Overall Dictionary\n",
        "  - Parameter Category\n",
        "    - Specific parameter item\n",
        "\n",
        "\n",
        "Let's see an example:"
      ],
      "metadata": {
        "id": "75kVqe7hxLo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import ModelSearchArguments, DatasetSearchArguments"
      ],
      "metadata": {
        "id": "smT-1TUTwyiO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_args = ModelSearchArguments()\n",
        "dataset_args = DatasetSearchArguments()"
      ],
      "metadata": {
        "id": "XGQ9NNDdzsOf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Note: These may take a moment to run, as they have to search through all the models and datasets hosted"
      ],
      "metadata": {
        "id": "IWzoO2FZzvGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will explore the `ModelSearchArguments`:"
      ],
      "metadata": {
        "id": "lEiu6fW_0HuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zirfuJ0jzuie",
        "outputId": "9531ec12-3065-41a6-b3c0-cc7a1105aa90"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Available Attributes or Keys:\n",
              " * author\n",
              " * dataset\n",
              " * language\n",
              " * library\n",
              " * license\n",
              " * model_name\n",
              " * pipeline_tag\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In it we find different **categories** for search parameters we may want. These correspond to how we will later pass them in for searching. \n",
        "\n",
        "Let's explore deeper in the `pipeline_tag`:"
      ],
      "metadata": {
        "id": "bnH792f00MV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args.pipeline_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjVjklTQ0Lrj",
        "outputId": "3e1525fb-27b8-4b50-cd6d-d9259a66acac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Available Attributes or Keys:\n",
              " * AudioClassification\n",
              " * Audio_to_Audio\n",
              " * AutomaticSpeechRecognition\n",
              " * Conversational\n",
              " * FeatureExtraction\n",
              " * Fill_Mask\n",
              " * ImageClassification\n",
              " * ImageSegmentation\n",
              " * Image_to_Text\n",
              " * ObjectDetection\n",
              " * QuestionAnswering\n",
              " * SentenceSimilarity\n",
              " * StructuredDataClassification\n",
              " * Summarization\n",
              " * TableQuestionAnswering\n",
              " * Text2TextGeneration (Key only)\n",
              " * TextClassification\n",
              " * TextGeneration\n",
              " * Text_to_Image\n",
              " * Text_to_Speech\n",
              " * TokenClassification\n",
              " * Translation\n",
              " * VoiceActivityDetection\n",
              " * Zero_ShotClassification\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we find every single `pipeline_tag` in existance that we can use. Finally, to see what the API would use as a query:"
      ],
      "metadata": {
        "id": "hpkqJmjY03iT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args.pipeline_tag.Text_to_Image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t2YHePTX0ZfL",
        "outputId": "1793996d-9af7-462a-9a56-fa878aa89562"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'text-to-image'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this exploratory fashion, you can now go and fine-tune what you would like to search for in an organized fashion for both Datasets and Models"
      ],
      "metadata": {
        "id": "o25eBkpH1Bzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a quick example of doing the same with `DatasetSearchArguments`:"
      ],
      "metadata": {
        "id": "r6wcBjtG1q1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umkQBpnS1BUQ",
        "outputId": "d658bcf3-7fae-48b8-ac4e-12ae2bcc4e22"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Available Attributes or Keys:\n",
              " * author\n",
              " * benchmark\n",
              " * dataset_name\n",
              " * language_creators\n",
              " * languages\n",
              " * licenses\n",
              " * multilinguality\n",
              " * size_categories\n",
              " * task_categories\n",
              " * task_ids\n"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Searching available benchmarks\n",
        "dataset_args.benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od9B1aUL1vE_",
        "outputId": "33e0d402-3282-474e-ae13-4a8f01a16920"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Available Attributes or Keys:\n",
              " * gem\n",
              " * raft\n",
              " * superb\n",
              " * test\n"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grabbing the gem benchmark\n",
        "dataset_args.benchmark.gem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SNOmkqGI1w8R",
        "outputId": "a265ecf2-05b2-40f9-a1c9-ce2411bca772"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'benchmark:gem'"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filters and Searching the Hub\n",
        "\n",
        "Now that we understand the search parameters we can use, *how* do we use them? \n",
        "\n",
        "We've added two classes to help us with that: `ModelFilter` and `DatasetFilter`. These are two namespace classes that simply hold our arguments, but what makes them special is that the `list_models` and `list_datasets` functions (which we will see later) know how to unpack these and query the API for us while our code stays clean and readable!\n",
        "\n",
        "Let's take a look."
      ],
      "metadata": {
        "id": "7874eoHZ2_VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import ModelFilter, DatasetFilter"
      ],
      "metadata": {
        "id": "IBvKq46G13WX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a clear understanding, we'll read its docstring below:"
      ],
      "metadata": {
        "id": "2o9Fsrj76Ln9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ModelFilter.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUMjEhiV6AWB",
        "outputId": "504749ac-4122-4a12-ed3d-f61aaebdc0b1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A class that converts human-readable model search parameters into ones compatible with\n",
            "    the REST API. For all parameters capitalization does not matter.\n",
            "\n",
            "    Args:\n",
            "        author (:obj:`str`, `optional`):\n",
            "            A string that can be used to identify models on the Hub\n",
            "            by the original uploader (author or organization), such as `facebook` or `huggingface`\n",
            "            Example usage:\n",
            "\n",
            "                >>> from huggingface_hub import Filter\n",
            "                >>> new_filter = ModelFilter(author_or_organization=\"facebook\")\n",
            "\n",
            "         library (:obj:`str` or :class:`List`, `optional`):\n",
            "            A string or list of strings of foundational libraries models were originally trained from,\n",
            "            such as pytorch, tensorflow, or allennlp\n",
            "            Example usage:\n",
            "\n",
            "                >>> new_filter = ModelFilter(library=\"pytorch\")\n",
            "\n",
            "         language (:obj:`str` or :class:`List`, `optional`):\n",
            "            A string or list of strings of languages, both by name\n",
            "            and country code, such as \"en\" or \"English\"\n",
            "            Example usage:\n",
            "\n",
            "                >>> new_filter = ModelFilter(language=\"french\")\n",
            "\n",
            "         model_name (:obj:`str`, `optional`):\n",
            "            A string that contain complete or partial names for models on the Hub,\n",
            "            such as \"bert\" or \"bert-base-cased\"\n",
            "            Example usage:\n",
            "\n",
            "                >>> new_filter = ModelFilter(model_name=\"bert\")\n",
            "\n",
            "\n",
            "         task (:obj:`str` or :class:`List`, `optional`):\n",
            "            A string or list of strings of tasks models were designed for,\n",
            "            such as: \"fill-mask\" or \"automatic-speech-recognition\"\n",
            "            Example usage:\n",
            "\n",
            "                >>> new_filter = ModelFilter(task=\"text-classification\")\n",
            "\n",
            "         tags (:obj:`str` or :class:`List`, `optional`):\n",
            "            A string tag or a list of tags to filter models on the Hub by,\n",
            "            such as `text-generation` or `spacy`. For a full list of tags do:\n",
            "                >>> from huggingface_hub import HfApi\n",
            "                >>> api = HfApi()\n",
            "                # To list model tags\n",
            "                >>> api.get_model_tags()\n",
            "                # To list dataset tags\n",
            "                >>> api.get_dataset_tags()\n",
            "\n",
            "            Example usage:\n",
            "                >>> new_filter = ModelFilter(tags=\"benchmark:raft\")\n",
            "\n",
            "        trained_dataset (:obj:`str` or :class:`List`, `optional`):\n",
            "            A string tag or a list of string tags of the trained dataset for a model on the Hub.\n",
            "            Example usage:\n",
            "                >>> new_filter = ModelFilter(trained_dataset=\"common_voice\")\n",
            "\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can imagine, it is quite easy to take our `ModelSearchArguments` (or `DatasetSearchArguments`) and then utilize them inside of our `ModelFilter` (or `DatasetFilter`)!\n",
        "\n",
        "> Remember: Since they are just strings, you can always just pass the string in directly if you know it!"
      ],
      "metadata": {
        "id": "NoXKXi9y6VBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the same example provided in the official [documentation](https://huggingface.co/docs/hub/searching-the-hub#searching-for-a-model) to search the Hub for a particular model.\n",
        "\n",
        "We'll set our query as:\n",
        "- I want all models for \"Text Classification\"\n",
        "- They should be trained on the \"GLUE\" dataset\n",
        "- They should be compatible with PyTorch\n",
        "\n",
        "Let's format our `ModelFilter` accordingly:"
      ],
      "metadata": {
        "id": "LL8PvXwi-TzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filt = ModelFilter(\n",
        "    task = model_args.pipeline_tag.TextClassification,\n",
        "    trained_dataset = model_args.dataset.glue,\n",
        "    library = model_args.library.PyTorch\n",
        ")"
      ],
      "metadata": {
        "id": "quUJAimq6Av6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way of writing this without the `model_args` would be like so:"
      ],
      "metadata": {
        "id": "UVxOCO43_Wn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filt = ModelFilter(\n",
        "    task = \"text-classification\",\n",
        "    trained_dataset = \"glue\", # or dataset:glue\n",
        "    library = \"pytorch\"\n",
        ")"
      ],
      "metadata": {
        "id": "hiMI76RU_Vhp"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's build a `HfApi` and search the Hub!"
      ],
      "metadata": {
        "id": "tmVJdG-E_lzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi"
      ],
      "metadata": {
        "id": "LH8I6qMj_lQl"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api = HfApi()"
      ],
      "metadata": {
        "id": "jEi7lLgr_qIl"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api.list_models(filter=filt)[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJwAnAGo_rgr",
        "outputId": "1628f6af-09d0-49b2-dbb0-87286ab16d41"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelInfo: {\n",
              "\tmodelId: harithapliyal/distilbert-base-uncased-finetuned-cola\n",
              "\tsha: 8d5a07a64338385fe0a732a62ec820495aa6b34e\n",
              "\tlastModified: 2022-01-18T18:44:28.000Z\n",
              "\ttags: ['pytorch', 'tensorboard', 'distilbert', 'text-classification', 'dataset:glue', 'transformers', 'license:apache-2.0', 'generated_from_trainer', 'model-index', 'infinity_compatible']\n",
              "\tpipeline_tag: text-classification\n",
              "\tsiblings: [ModelFile(rfilename='.gitattributes'), ModelFile(rfilename='.gitignore'), ModelFile(rfilename='README.md'), ModelFile(rfilename='config.json'), ModelFile(rfilename='pytorch_model.bin'), ModelFile(rfilename='special_tokens_map.json'), ModelFile(rfilename='tokenizer.json'), ModelFile(rfilename='tokenizer_config.json'), ModelFile(rfilename='training_args.bin'), ModelFile(rfilename='vocab.txt'), ModelFile(rfilename='runs/Jan18_14-16-18_f5e821c8415e/events.out.tfevents.1642515510.f5e821c8415e.60.0'), ModelFile(rfilename='runs/Jan18_14-16-18_f5e821c8415e/events.out.tfevents.1642521209.f5e821c8415e.60.2'), ModelFile(rfilename='runs/Jan18_14-16-18_f5e821c8415e/1642515510.2724547/events.out.tfevents.1642515510.f5e821c8415e.60.1'), ModelFile(rfilename='runs/Jan18_17-09-35_add2990e9a92/events.out.tfevents.1642525942.add2990e9a92.61.0'), ModelFile(rfilename='runs/Jan18_17-09-35_add2990e9a92/events.out.tfevents.1642531259.add2990e9a92.61.2'), ModelFile(rfilename='runs/Jan18_17-09-35_add2990e9a92/1642525942.325853/events.out.tfevents.1642525942.add2990e9a92.61.1')]\n",
              "\tconfig: None\n",
              "\tprivate: False\n",
              "\tdownloads: 0\n",
              "\tlibrary_name: transformers\n",
              "\tlikes: 0\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we look at `distilbert-base-uncased-finetuned-cola` as our example, it matches all of our queries for what we wanted!\n",
        "\n",
        "Where this API really comes in handy is handling very complex queries, such as:\n",
        "- All models for Text Classification\n",
        "- That are both for PyTorch and TensorFlow\n",
        "- Were trained on the \"SST-2\" dataset"
      ],
      "metadata": {
        "id": "Sg_bEPNY_vWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filt = ModelFilter(\n",
        "    task = model_args.pipeline_tag.TextClassification,\n",
        "    library = [model_args.library.PyTorch, model_args.library.TensorFlow],\n",
        "    trained_dataset = model_args.dataset.sst_2\n",
        ")"
      ],
      "metadata": {
        "id": "5_PRTqqU_tiB"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api.list_models(filter=filt)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHL6BHevBQWg",
        "outputId": "d74cab1e-6b8e-4ec2-912e-671ebe0e3ee0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelInfo: {\n",
              "\tmodelId: distilbert-base-uncased-finetuned-sst-2-english\n",
              "\tsha: 03b4d196c19d0a73c7e0322684e97db1ec397613\n",
              "\tlastModified: 2021-02-09T07:59:22.000Z\n",
              "\ttags: ['pytorch', 'tf', 'rust', 'distilbert', 'text-classification', 'en', 'dataset:sst-2', 'transformers', 'license:apache-2.0', 'infinity_compatible']\n",
              "\tpipeline_tag: text-classification\n",
              "\tsiblings: [ModelFile(rfilename='.gitattributes'), ModelFile(rfilename='README.md'), ModelFile(rfilename='config.json'), ModelFile(rfilename='pytorch_model.bin'), ModelFile(rfilename='rust_model.ot'), ModelFile(rfilename='tf_model.h5'), ModelFile(rfilename='tokenizer_config.json'), ModelFile(rfilename='vocab.txt')]\n",
              "\tconfig: None\n",
              "\tprivate: False\n",
              "\tdownloads: 2858092\n",
              "\tlibrary_name: transformers\n",
              "\tlikes: 29\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And it finds the exact model we want, without having to get *too* complex with our setup!\n",
        "\n",
        "This is done exactly in the same fashion for datasets as well. Below is a quick example of finding all English datasets for text classification:"
      ],
      "metadata": {
        "id": "v8VlFZQHB1Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filt = DatasetFilter(\n",
        "    task_categories = \"text-classification\",\n",
        "    languages = \"en\"\n",
        ")"
      ],
      "metadata": {
        "id": "0QZEV0pEBReU"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api.list_datasets(filt)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO3S-SaTCI_1",
        "outputId": "92ab74be-f966-4ee7-a2f0-370ced015370"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetInfo: {\n",
              "\tid: Abirate/english_quotes\n",
              "\tlastModified: None\n",
              "\ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language_creators:crowdsourced', 'languages:en', 'multilinguality:monolingual', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification']\n",
              "\tprivate: False\n",
              "\tauthor: Abirate\n",
              "\tdescription: None\n",
              "\tcitation: None\n",
              "\tcardData: None\n",
              "\tsiblings: None\n",
              "\tgated: False\n",
              "\tdownloads: 5\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With these new supercharged searching capabilities, you now don't have to even leave your coding interface to go find the right model or dataset for your task!"
      ],
      "metadata": {
        "id": "oatmmbW1NEIx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Hub Blog",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}